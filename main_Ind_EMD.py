import argparse
import os
import random
import shutil
import time
import warnings
import csv
from PIL import Image
from pathlib import Path
from tqdm import tqdm, trange
import numpy as np
import pandas as pd
from scipy import stats
from sklearn.metrics import confusion_matrix, mean_absolute_error, mean_squared_error
from collections import OrderedDict
from distutils.util import strtobool
import pickle

import torch
import torch.nn as nn
import torch.backends.cudnn as cudnn
import torch.optim
import torch.utils.data
import torch.utils.data.distributed
import torchvision.transforms as transforms

import net
from datasets import AVADataset, AVAMPAesInceptionDataset, AVAMPAesLocalGlobalInceptionDataset ,AVAMPAesLocalInceptionDataset
from utils import get_mean_score, get_std_score

import matplotlib as mpl
mpl.use('Agg')
import matplotlib.pyplot as plt
plt.rcParams['ps.fonttype'] = 42
plt.rcParams['pdf.fonttype'] = 42
plt.rcParams['font.family'] = 'Times New Roman' # set the overall font family for graphs generated by matplotlib
plt.rcParams["mathtext.fontset"] = "stix"
import seaborn as sns; sns.set(style="white", color_codes=True, font='Times New Roman')


parser = argparse.ArgumentParser(description='PyTorch Image Retargeting Model-Learner')
parser.add_argument('--path-to-train-csv', metavar='DIR',
                    help='path to AVA train csv.')
parser.add_argument('--path-to-test-csv', metavar='DIR',
                    help='path to AVA test csv.')
parser.add_argument('--path-to-images', metavar='DIR',
                    help='dir to AVA images.')
parser.add_argument('-j', '--num-workers', default=16, type=int, metavar='N',
                    help='number of data loading workers (default: 16)')
parser.add_argument('-b', '--batch-size', default=1, type=int,
                    metavar='N', help='mini-batch size (default: 1)')
parser.add_argument('--val-batch-size', default=1, type=int,
                    metavar='N', help='validation mini-batch size (default: 1)')
parser.add_argument('--epochs', default=10, type=int, metavar='N',
                    help='number of total epochs to run')
parser.add_argument('--conv-lr', default=1e-3, type=float,
                    metavar='CONV_LR', help='initial conv learning rate')
parser.add_argument('--dense-lr', default=1e-3, type=float,
                    metavar='DENSE_LR', help='initial dense learning rate')
parser.add_argument('--resultdir', default="result/temp", metavar='RESULT DIR',
                    help='dir path for result')
parser.add_argument('--start-epoch', default=0, type=int, metavar='N',
                    help='manual epoch number (useful on restarts)')
parser.add_argument('--momentum', default=0.9, type=float, metavar='M',
                    help='momentum')
# parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float, metavar='W',
#                     help='weight decay (default: 1e-4)')
parser.add_argument('--print-freq', '-p', default=20, type=int,
                    metavar='N', help='print frequency (default: 20)')
parser.add_argument('--csv-write-freq', dest='csv_write_freq', default=40, type=int,
                    metavar='N', help='csv write frequency (default: 40)')
parser.add_argument('--save-freq', default=10, type=int,
                    metavar='N', help='model save frequency (default: 10)')
parser.add_argument('--resume', default='', type=str, metavar='PATH',
                    help='path to latest checkpoint (default: none)')
parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true', default=False,
                    help='evaluate model on validation set')
parser.add_argument('--seed', default=None, type=int,
                    help='seed for initializing training. ')
parser.add_argument('--gpu', default=False, help='Whether to use GPU.', action="store_true")
parser.add_argument('--crop-num', default=16, type=int,
                    metavar='N', help='number of random cropping for training.')
parser.add_argument('--random-crop-nums', type=int, nargs='*', default=None, help='numbers list of MP_random crops.')
parser.add_argument('--local-crop-nums', type=int, nargs='*', default=None, help='numbers list of MP_local crops.')
parser.add_argument('--local-global-crop-nums', type=int, nargs='*', default=None, help='numbers list of MP_local_global crops.')
parser.add_argument('--beta', default=2., type=float, help='hyperparameter beta')
parser.add_argument('--pr_weight', default=2., type=float, help='hyperparameter pr_weight')
parser.add_argument('--lr-decay-rate', default=0.5, type=float,
                    metavar='LR_DECAY_RATE', help='lr decay rate')
parser.add_argument('--lr-decay-freq', default=10, type=int,
                    metavar='LR_DECAY_FREQ', help='lr decay freq')
parser.add_argument('--dataset-seed', default=None, type=int, help="dataset random crop seed")
parser.add_argument('--evaluate-stem', default="", type=str, help="stem of evaluation export files.")
parser.add_argument('--h-key', default="", type=str, help="(hidden variable area)")
parser.add_argument('--path-to-nima', default=None, type=str, help="path to NIMA pretrained model")
parser.add_argument('--nima-pretrained', default=False, type=strtobool, help="whether to use nima pretrained model (defualt: True).")

best_mean_lcc_val = -1
best_std_dev_lcc_val = -1
best_emd_loss_val = 100000000

device = torch.device("cpu")


def main():
    global args, best_emd_loss_val, best_mean_lcc_val, best_std_dev_lcc_val
    global device
    args = parser.parse_args()
    args.h_key = ""

    print("seed:", args.seed)

    if args.seed is not None:
        random.seed(args.seed)
        torch.manual_seed(args.seed)
        torch.cuda.manual_seed_all(args.seed)
        cudnn.deterministic = True
        warnings.warn('You have chosen to seed training. '
                      'This will turn on the CUDNN deterministic setting, '
                      'which can slow down your training considerably! '
                      'You may see unexpected behavior when restarting '
                      'from checkpoints.')

    if args.gpu is not None:
        warnings.warn('You have chosen a specific GPU. This will completely '
                      'disable data parallelism.')
        device = torch.device("cuda")
    else:
        device = torch.device("cpu")

    # define model
    model = net.NIMAInceptionV3(pretrained_base_model=True)

    if args.nima_pretrained:  # True at train
        if args.path_to_nima is None:
            raise ValueError
        checkpoint = torch.load(args.path_to_nima, map_location=lambda storage, loc: storage)
        model.load_state_dict(checkpoint["state_dict"])

    model = model.to(device)

    if not args.evaluate:
        for param in model.parameters():
            param.require_grad = True
    # define validation model for multi-patch validation
    val_model = net.MPCroppedAesScoreNIMAInceptionV3(nima_pretrained=False)
    val_model = val_model.to(device)

    # define loss function (criterion)
    """ This criterion is for the training equivalent to MPEMD_avg. The criterion will be swtched as weighted EMD for training equivalent to MPEMD_ada."""
    criterion = net.AdaEMDLoss(beta=args.beta, pr_weight=args.pr_weight)
    criterion = criterion.to(device)

    # define loss fuction for milti-patch validation
    val_criterion = net.MPEMDLoss()
    val_criterion = val_criterion.to(device)

    # define optimizer
    optimizer = torch.optim.SGD(params=[
        {'params': filter(lambda p: p.requires_grad, model.base_model.parameters()), "lr": args.conv_lr},
        {'params': filter(lambda p: p.requires_grad, model.head.parameters()), "lr": args.dense_lr}
    ], momentum=args.momentum)

    print("len of optimizer.param_groups:", len(optimizer.param_groups))
    # print(optimizer.param_groups[0].keys())
    # print(optimizer.param_groups)

    # optionally resume from a checkpoint
    if args.resume:
        if os.path.isfile(args.resume):
            print("=> loading checkpoint '{}'".format(args.resume))
            checkpoint = torch.load(args.resume)
            args.start_epoch = checkpoint['epoch']
            # best_total_loss_val = checkpoint['total_loss']
            best_mean_lcc_val = checkpoint["mean_lcc"]
            best_std_dev_lcc_val = checkpoint["std_dev_lcc"]
            best_emd_loss_val = checkpoint["MP_EMD_loss"]
            model.load_state_dict(checkpoint['state_dict'])
            optimizer.load_state_dict(checkpoint['optimizer'])
            print("=> loaded checkpoint '{}' (epoch {})"
                  .format(args.resume, checkpoint['epoch']))
        else:
            print("=> no checkpoint found at '{}'".format(args.resume))

    cudnn.benchmark = True

    # Data loading code
    os.makedirs(args.resultdir, exist_ok=True)

    image_normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])

    train_csv_path = args.path_to_train_csv
    train_dataset = AVADataset(path_to_csv=train_csv_path, images_path=args.path_to_images,
                               transform=transforms.Compose([
                                   transforms.Resize(342),  # unique value for inception
                                   transforms.RandomHorizontalFlip(),
                                   transforms.RandomCrop((299, 299)), # unique value for inception
                                   transforms.ToTensor(),
                                   image_normalize]))
    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True,
                                               num_workers=args.num_workers,
                                               pin_memory=False)  # Consider turn pin_memory False if meet out of memory errors.

    val_csv_path = args.path_to_test_csv
    val_dataset = AVAMPAesInceptionDataset(path_to_csv=val_csv_path, images_path=args.path_to_images,
                                           crop_num=args.crop_num,
                                           transform=transforms.Compose([
                                               transforms.Resize(342),
                                               transforms.ToTensor(),
                                               image_normalize
                                           ]),
                                           np_seed=args.dataset_seed)
    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args.val_batch_size, shuffle=False,
                                             num_workers=args.num_workers, pin_memory=True)

    # record validation result
    if args.evaluate:
        print("* enter evaluation mode")
        eval_batch_size = args.val_batch_size # need to customize
        eval_datasets = dict()

        if args.random_crop_nums:
            for crop_n in args.random_crop_nums:
                key_name = "MP_random_" + "crop_" + str(crop_n)
                eval_datasets[key_name] = AVAMPAesInceptionDataset(path_to_csv=val_csv_path, images_path=args.path_to_images, crop_num=crop_n,
                                transform=transforms.Compose([
                                    transforms.Resize(342),
                                    transforms.ToTensor(),
                                    image_normalize
                                ]), np_seed=args.dataset_seed)

        if args.local_crop_nums:
            for sidecrop_n in args.local_crop_nums:
                key_name = "MP_local_" + "sidecrop_" + str(sidecrop_n)
                eval_datasets[key_name] = AVAMPAesLocalInceptionDataset(path_to_csv=val_csv_path, images_path=args.path_to_images, side_crop_num=sidecrop_n,
                                transform=transforms.Compose([
                                    transforms.Resize(342),
                                    transforms.ToTensor(),
                                    image_normalize
                                ]))
        if args.local_global_crop_nums:
            for sidecrop_n in args.local_global_crop_nums:
                key_name = "MP_local_global_" + "sidecrop_" + str(sidecrop_n)
                eval_datasets[key_name] = AVAMPAesLocalGlobalInceptionDataset(path_to_csv=val_csv_path, images_path=args.path_to_images, side_crop_num=sidecrop_n,
                                transform=transforms.Compose([
                                    transforms.Resize(342),
                                    transforms.ToTensor(),
                                    image_normalize
                                ]),
                                transform_global=transforms.Compose([
                                    transforms.Resize((299, 299)),
                                    transforms.ToTensor(),
                                    image_normalize
                                ]))

        for key, eval_dataset in eval_datasets.items():
            print("eval:", key)
            args.h_key = key
            # prepare eval result csv file
            eval_csv_path = os.path.join(args.resultdir, "evaluate_" + args.evaluate_stem + "_" + args.h_key +"_result.csv")
            eval_namefields = generate_common_namefileds()
            if not (args.resume and os.path.isfile(eval_csv_path)):
                init_csv(eval_csv_path, eval_namefields)
            eval_model = net.MPCroppedAesScoreNIMAInceptionV3(nima_pretrained=False)
            eval_model = eval_model.to(device)

            # prepare eval loader
            eval_loader = torch.utils.data.DataLoader(eval_dataset, batch_size=eval_batch_size, shuffle=False,
                                                      num_workers=args.num_workers, pin_memory=True)

            scat_graph, eval_result_dict = validate(eval_loader, model, val_criterion, eval_model)

            # ! save scatter graph
            save_scat_graph(scat_graph,
                            filepath=os.path.join(args.resultdir, "evaluate_" + args.evaluate_stem + "_" + args.h_key + "_scat_graph.png"))
            save_scat_graph(scat_graph,
                            filepath=os.path.join(args.resultdir,
                                                  "evaluate_" + args.evaluate_stem + "_" + args.h_key + "_scat_graph.pdf"))

            temp_eval_result_dict = {key: '{:.10f}'.format(val) for key, val in eval_result_dict.items()}
            write_csv(eval_csv_path, eval_namefields, temp_eval_result_dict)

        return

    """ below is training code """
    # prepare result csv files
    learn_csv_path = os.path.join(args.resultdir, "learning_result.csv")
    learn_namefields = ["epoch", "iter", "EMD_loss", "batch_time", "data_time", "ada_loss"]

    val_csv_path = os.path.join(args.resultdir, "validate_result.csv")
    epoch_dict_keys = ["epoch", "train_EMD_loss", "train_ada_loss"]

    val_namefields = epoch_dict_keys + generate_common_namefileds()

    if not (args.resume and os.path.isfile(learn_csv_path)):
        init_csv(learn_csv_path, learn_namefields)
    if not (args.resume and os.path.isfile(val_csv_path)):
        init_csv(val_csv_path, val_namefields)

    # learning result for plotting
    learn_progress_dict = dict()
    learn_progress_dict["epoch"] = []
    learn_progress_dict["train_EMD_loss"] = []
    learn_progress_dict["train_ada_loss"] = []
    learn_progress_dict["val_MP_EMD_loss"] = []

    # for epoch in range(args.start_epoch, args.epochs):
    for epoch in trange(args.start_epoch, args.epochs, desc="train epochs"):
        # train for one epoch
        train_result_dict = train(train_loader, model, criterion, optimizer, epoch, csv_path=learn_csv_path,
              csv_namefields=learn_namefields)
        adjust_learning_rate(optimizer, epoch, [args.conv_lr, args.dense_lr], args.lr_decay_rate, args.lr_decay_freq)

        # evaluate on validation set
        scat_graph, val_result_dict = validate(val_loader, model, val_criterion, val_model)
        val_result_dict["train_EMD_loss"] = train_result_dict["EMD_loss"]
        val_result_dict["train_ada_loss"] = train_result_dict["ada_loss"]
        # ! save scatter graph
        save_scat_graph(scat_graph, filepath=os.path.join(args.resultdir, "e_" + str(epoch) + ".png"))
        temp_val_result_dict = {key: '{:.10f}'.format(val) for key, val in val_result_dict.items()}
        temp_val_result_dict["epoch"] = epoch
        write_csv(val_csv_path, val_namefields, temp_val_result_dict)

        # plot progress result
        learn_progress_dict["epoch"].append(epoch)
        learn_progress_dict["train_EMD_loss"].append(train_result_dict["EMD_loss"])
        learn_progress_dict["train_ada_loss"].append(train_result_dict["ada_loss"])
        # learn_progress_dict["val_EMD_loss"].append(val_result_dict["EMD_loss"])
        learn_progress_dict["val_MP_EMD_loss"].append(val_result_dict["MP_EMD_loss"])
        progress_data_keys = list(learn_progress_dict.keys())
        progress_data_keys.remove("epoch")
        plot_learn_progress(learn_progress_dict,
                            filepath=os.path.join(args.resultdir, "progress.png"),
                            graph_title=os.path.basename(args.resultdir),
                            x_key="epoch",
                            data_keys=progress_data_keys,
                            ylabel="EMD and log(EMD) loss")

        # remember best prec@1 and save checkpoint
        # "option for skip saveing model"
        is_emd_loss_best = val_result_dict["MP_EMD_loss"] < best_emd_loss_val
        best_emd_loss_val = min(val_result_dict["MP_EMD_loss"], best_emd_loss_val)
        is_mean_lcc_best = val_result_dict["mean_lcc"] > best_mean_lcc_val
        best_mean_lcc_val = max(val_result_dict["mean_lcc"], best_mean_lcc_val)
        is_std_dev_lcc_best = val_result_dict["std_dev_lcc"] > best_std_dev_lcc_val
        best_std_dev_lcc_val = max(val_result_dict["std_dev_lcc"], best_std_dev_lcc_val)

        save_checkpoint({
            'epoch': epoch + 1,
            'state_dict': model.state_dict(),
            'train_EMD_loss': val_result_dict["train_EMD_loss"],
            'MP_EMD_loss': val_result_dict["MP_EMD_loss"],
            'mean_lcc': val_result_dict["mean_lcc"],
            'std_dev_lcc': val_result_dict["std_dev_lcc"],
            'optimizer': optimizer.state_dict(),
        }, is_emd_loss_best, is_mean_lcc_best, is_std_dev_lcc_best, epoch, args.save_freq, resultdir=args.resultdir)


def train(train_loader, model, criterion, optimizer, epoch, csv_path=None, csv_namefields=None):
    global args, device

    batch_time = AverageMeter()
    data_time = AverageMeter()
    EMD_loss = AverageMeter()
    ada_loss = AverageMeter()

    # switch to train mode
    model.train()

    end = time.time()
    for i, (input, target_np) in tqdm(enumerate(train_loader)):
        # measure data loading time
        data_time.update(time.time() - end)

        input = input.to(device)
        target = target_np
        target = target.to(device)  # target is not cumulated

        # compute output
        output = model(input)  # output: scores of [1, 2, ... , 9, 10]
        # (output) = (N, 10)

        # calculate loss
        ada_loss_batch, _, EMD_loss_batch, _ = criterion(output, target)

        # compute gradient and do SGD step
        optimizer.zero_grad()
        # EMD_loss_batch.backward()
        ada_loss_batch.backward()
        optimizer.step()

        # !! losses were already averaged
        ada_loss.update(ada_loss_batch.item(), input.size(0))
        EMD_loss.update(EMD_loss_batch.item(), input.size(0))

        # measure elapsed time
        batch_time.update(time.time() - end)
        end = time.time()

        if i % args.print_freq == 0:
            print('Epoch: [{0}][{1}/{2}]\t'
                  'Time {batch_time.val:.5f} ({batch_time.avg:.5f})\t'
                  'Data {data_time.val:.5f} ({data_time.avg:.5f})\t'
                  'ada_loss {ada_loss.val:.7f} ({ada_loss.avg:.7f})\t'
                  'EMD_loss {EMD_loss.val:.7f} ({EMD_loss.avg:.7f})\t'
                .format(
                epoch, i, len(train_loader), batch_time=batch_time,
                data_time=data_time, ada_loss=ada_loss, EMD_loss=EMD_loss))

        if csv_path:
            if i % args.csv_write_freq == 0:
                # write learning result to csv file
                temp_learn_result_dict = {"epoch": epoch, "iter": iter}
                temp_learn_result_dict.update(
                    {key: "{:.10f}".format(val.val) for key, val in
                     zip(csv_namefields[2:], [EMD_loss, batch_time, data_time, ada_loss])})
                write_csv(csv_path, csv_namefields, temp_learn_result_dict)

    result_dict = OrderedDict()
    # save MP_EMD_loss to dict
    result_dict.update([("EMD_loss", EMD_loss.avg)])
    result_dict.update([("ada_loss", ada_loss.avg)])

    print('[train] * ada_loss {ada_loss.avg:.7f}\t'
          'EMD_loss {EMD_loss.avg:.7f}\t'
          .format(ada_loss=ada_loss, EMD_loss=EMD_loss))

    return result_dict


def validate(val_loader, train_model, val_criterion, val_model):
    global args, device

    model = val_model
    model.nima = train_model

    if isinstance(val_criterion, list):
        #! culculate train-criterion loss at val data.
        criterion_flag = True
        criterions = val_criterion
        criterion = criterions[0] # criterion for train
        val_criterion = criterions[1]
    else:
        criterion_flag = False

    batch_time = AverageMeter()
    MP_EMD_loss = AverageMeter()
    if criterion_flag:
        MP_train_crit_loss = AverageMeter()

    mean_target_array = np.array([])
    mean_output_array = np.array([])
    std_dev_target_array = np.array([])
    std_dev_output_array = np.array([])

    # switch to evaluate mode
    model.eval()

    with torch.no_grad():
        end = time.time()
        for i, (input, target) in tqdm(enumerate(val_loader)):
            input = input.to(device)
            target = target.to(device)
            # (target).shape = [N, 10]
            # target = torch.from_numpy(target_np).float().to(device)
            target_np = target.cpu().numpy()

            # compute output
            output = model(input)
            # (output).shape = [N, 10]
            output_np = output.mean(dim=1).cpu().numpy()
            # output_np = output.cpu().numpy()
            # (output_np).shape = [N, 10]

            # add result to list
            mean_target = np.array([get_mean_score(row) for row in target_np])
            mean_output = np.array([get_mean_score(row) for row in output_np])
            std_dev_target = np.array([get_std_score(row) for row in target_np])
            std_dev_output = np.array([get_std_score(row) for row in output_np])
            mean_target_array = np.hstack((mean_target_array, mean_target))
            mean_output_array = np.hstack((mean_output_array, mean_output))
            std_dev_target_array = np.hstack((std_dev_target_array, std_dev_target))
            std_dev_output_array = np.hstack((std_dev_output_array, std_dev_output))

            # calculate loss
            MP_EMD_loss_batch, _ = val_criterion(output, target)

            # measure accuracy and record loss
            # !! losses were already averaged
            MP_EMD_loss.update(MP_EMD_loss_batch.item(), input.size(0))

            if criterion_flag:
                # calculate train-criterion loss
                MP_loss_batch, attention_weight_batch, _, _ = criterion(output, target)
                MP_train_crit_loss.update(MP_loss_batch.item(), input.size(0))

            # measure elapsed time
            batch_time.update(time.time() - end)
            end = time.time()

            if i % args.print_freq == 0:
                print('Test: [{0}/{1}]\t'
                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\t'
                      'MP_EMD_loss {MP_EMD_loss.val:.7f} ({MP_EMD_loss.avg:.7f})\n'
                    .format(
                    i, len(val_loader), batch_time=batch_time, MP_EMD_loss=MP_EMD_loss))

    result_dict = OrderedDict()
    # save MP_EMD_loss to dict
    result_dict.update([("MP_EMD_loss", MP_EMD_loss.avg)])

    # calculate linear correlation coefficient
    mean_lcc = np.corrcoef(mean_target_array, mean_output_array)[0][1]
    std_dev_lcc = np.corrcoef(std_dev_target_array, std_dev_output_array)[0][1]
    result_dict.update([("mean_lcc", mean_lcc), ("std_dev_lcc", std_dev_lcc)])

    # spearman correlation
    mean_srcc, mean_srcc_pval = stats.spearmanr(mean_target_array, mean_output_array)
    std_dev_srcc, std_dev_srcc_pval = stats.spearmanr(std_dev_target_array, std_dev_output_array)
    result_dict.update([("mean_srcc", mean_srcc), ("mean_srcc_pval", mean_srcc_pval), ("std_dev_srcc", std_dev_srcc),
                        ("std_dev_srcc_pval", std_dev_srcc_pval)])

    # calculate confusion matrix
    mean_target_bin = np.where(mean_target_array <= 5, 0, 1)
    mean_output_bin = np.where(mean_output_array <= 5, 0, 1)
    # ! 0(nega) if value <= 5, and 1(posi) if value > 5

    bin_dict = OrderedDict()
    tn, fp, fn, tp = confusion_matrix(y_true=mean_target_bin, y_pred=mean_output_bin).ravel()
    bin_dict["tn"] = tn
    bin_dict["fp"] = fp
    bin_dict["fn"] = fn
    bin_dict["tp"] = tp
    bin_dict["accuracy"] = (tp + tn) / (tp + fp + tn + fn)
    bin_dict["precision"] = tp / (tp + fp)
    bin_dict["recall"] = tp / (tp + fn)
    bin_dict["specificity"] = tn / (fp + tn)
    bin_dict["f_value"] = 2 * bin_dict["recall"] * bin_dict["precision"] / (bin_dict["recall"] + bin_dict["precision"])
    result_dict.update(bin_dict)

    # calculate MAE
    mae_value = mean_absolute_error(mean_target_array, mean_output_array)
    result_dict.update([("mae", mae_value)])

    # generate ae histogram
    ae_raw_values = np.abs(mean_target_array - mean_output_array)
    with open(os.path.join(args.resultdir, "evaluate_" + args.evaluate_stem + "_" + args.h_key + "_ae_list.pkl"), 'wb') as f:
        pickle.dump(ae_raw_values, f)
    plot_histogram(ae_raw_values,
                   # bins=10,
                   bins=np.arange(0.0, 3.3, 0.3),
                   filepath=os.path.join(args.resultdir, "evaluate_" + args.evaluate_stem + "_" + args.h_key + "_ae_histogram.png"),
                   graph_title=os.path.basename(args.resultdir),
                   xlabel="Absolute Error",
                   ylabel="frequecy")
    plot_histogram(ae_raw_values,
                   # bins=10,
                   bins=np.arange(0.0, 3.3, 0.3),
                   filepath=os.path.join(args.resultdir,
                                         "evaluate_" + args.evaluate_stem + "_" + args.h_key + "_ae_histogram.pdf"),
                   graph_title=os.path.basename(args.resultdir),
                   xlabel="Absolute Error",
                   ylabel="frequecy")
    
    # calculate RMSE
    mse_value = mean_squared_error(mean_target_array, mean_output_array)
    rmse_value = np.sqrt(mse_value)
    result_dict.update([("rmse", rmse_value)])

    # generate Squared Error(SE) histogram
    se_raw_values = np.square(mean_target_array - mean_output_array)
    with open(os.path.join(args.resultdir, "evaluate_" + args.evaluate_stem + "_" + args.h_key + "_se_list.pkl"), 'wb') as f:
        pickle.dump(se_raw_values, f)
    plot_histogram(se_raw_values,
                   bins=np.arange(0.0, 9.3, 0.3),
                   filepath=os.path.join(args.resultdir, "evaluate_" + args.evaluate_stem + "_" + args.h_key + "_se_histogram.png"),
                   graph_title=os.path.basename(args.resultdir),
                   xlabel="Squared Error",
                   ylabel="frequecy")
    plot_histogram(se_raw_values,
                   bins=np.arange(0.0, 9.3, 0.3),
                   filepath=os.path.join(args.resultdir,
                                         "evaluate_" + args.evaluate_stem + "_" + args.h_key + "_se_histogram.pdf"),
                   graph_title=os.path.basename(args.resultdir),
                   xlabel="Squared Error",
                   ylabel="frequecy")
    
    # make scatter graph
    scat_graph = generate_scat_graph(truth=mean_target_array, prediction=mean_output_array)

    # print(
    #     '[test] * EMD_loss {EMD_loss.avg:.7f} mean_lcc {mean_lcc:.7f} std_dev_lcc {std_dev_lcc:.7f} accuracy={accuracy:.7f} MAE {mae:.7f} RMSE {rmse:.7f}'
    #         .format(EMD_loss=EMD_loss, mean_lcc=mean_lcc, std_dev_lcc=std_dev_lcc, accuracy=bin_dict["accuracy"], mae=mae_value, rmse=rmse_value))
    print(
        '[test] * MP_EMD_loss {MP_EMD_loss.avg:.7f} mean_lcc {mean_lcc:.7f} std_dev_lcc {std_dev_lcc:.7f} accuracy {accuracy:.7f} MAE {mae:.7f} RMSE {rmse:.7f}'
        .format(MP_EMD_loss=MP_EMD_loss, mean_lcc=mean_lcc, std_dev_lcc=std_dev_lcc, accuracy=bin_dict["accuracy"],
                mae=mae_value, rmse=rmse_value))

    return scat_graph, result_dict


def save_checkpoint(state, is_emd_loss_best, is_mean_lcc_best, is_std_dev_lcc_best, epoch, save_freq, resultdir, filename='checkpoint.pth.tar'):
    filename = os.path.join(resultdir, filename)
    torch.save(state, filename)
    if is_emd_loss_best:
        shutil.copyfile(filename, os.path.join(resultdir, 'model_emd_loss_best.pth.tar'))
    if is_mean_lcc_best:
        shutil.copyfile(filename, os.path.join(resultdir, 'model_mean_lcc_best.pth.tar'))
    if is_std_dev_lcc_best:
        shutil.copyfile(filename, os.path.join(resultdir, 'model_std_dev_lcc_best.pth.tar'))
    if epoch % save_freq == 0:
        shutil.copyfile(filename, os.path.join(resultdir, str(epoch) + '.pth.tar'))


def init_csv(csv_path, fieldnames):
    with open(csv_path, 'w', newline='') as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()


def write_csv(csv_path, fieldnames, data_dict):
    with open(csv_path, 'a', newline='') as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writerow(data_dict)


def adjust_learning_rate(optimizer, epoch, init_lr, lr_decay_rate, lr_decay_freq):
    """Sets the learning rate to the initial LR decayed by `lr_decay_rate` every `lr_decay_freq` epochs.

    .. NOTE: ．
    [EN] The type of var `init_lr` is float or list[float]. If the type is list[float], the func considers that the values of `init_lr` are set for each param_groups defined by optimizer.
    And as the epoch proceed, new `lr`s are calculated for each param_groups.

    [JP] init_lrはfloat, もしくはlist[float]．list[float]の場合は，optimizerで設定したparam_groupsごとにinit_lrが入っていると解釈する．
    そして，param_groupsごとに新しいlrを計算する
    """

    if isinstance(init_lr, list):
        new_lr_list = [lr * (lr_decay_rate ** (epoch // lr_decay_freq)) for lr in init_lr]
        for param_group, new_lr in zip(optimizer.param_groups, new_lr_list):
            param_group['lr'] = new_lr
    else:
        new_lr = init_lr * (lr_decay_rate ** (epoch // lr_decay_freq))
        for param_group in optimizer.param_groups:
            param_group['lr'] = new_lr


def generate_scat_graph(truth, prediction, x_range=[0, 11], y_range=[0, 11]) -> None:
    """
    : param truth: [EN] true aesthetics score       [JP] 真値平均審美度スコア
    : param prediction: [EN] predicted aesthetics score     [JP] 予測平均審美度スコア
    """
    df = pd.DataFrame({"truth": truth, "prediction": prediction})
    graph = sns.jointplot(x="prediction", y="truth", data=df, kind="reg", xlim=(x_range[0], x_range[1]),
                          ylim=(y_range[0], y_range[1]))
    graph = graph.annotate(stats.pearsonr)

    return graph


def plot_histogram(values, bins, filepath, graph_title, xlabel="diff", ylabel="freq"):
    plt.clf()
    plt.hist(values, bins=bins)
    plt.title(graph_title)
    if xlabel:
        plt.xlabel(xlabel)
    else:
        plt.xlabel("diff")
    if ylabel:
        plt.ylabel(ylabel)
    else:
        plt.ylabel("loss")
    plt.savefig(filepath)
    plt.clf()


def save_scat_graph(scat_graph, filepath):
    scat_graph.savefig(filepath)


def generate_common_namefileds():
    loss_dict_keys = ["MP_EMD_loss"]
    lcc_dict_keys = ["mean_lcc", "std_dev_lcc"]
    bin_dict_keys = ["tn", "fp", "fn", "tp", "accuracy", "precision", "recall", "specificity", "f_value"]
    srcc_dict_keys = ["mean_srcc", "mean_srcc_pval", "std_dev_srcc", "std_dev_srcc_pval"]
    metric_dict_keys = ["mae", "rmse"]
    namefields = loss_dict_keys + lcc_dict_keys + bin_dict_keys + srcc_dict_keys + metric_dict_keys

    return namefields


def plot_learn_progress(learn_progress_dict, filepath, graph_title, x_key="epoch", data_keys=["train_EMD_loss", "val_EMD_loss"], xlabel=None, ylabel="EMD loss"):
    plt.clf()
    ps = [plt.plot(learn_progress_dict[x_key], learn_progress_dict[data_key]) for data_key in data_keys]
    plt.legend(tuple([p[0] for p in ps]), tuple(data_keys), loc="upper right")
    plt.title(graph_title)
    if xlabel:
        plt.xlabel(xlabel)
    else:
        plt.xlabel(x_key)
    if ylabel:
        plt.ylabel(ylabel)
    else:
        plt.ylabel("loss")
    plt.savefig(filepath)
    plt.clf()


class AverageMeter(object):
    """Computes and stores the average and current value"""

    def __init__(self):
        self.reset()

    def reset(self):
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0

    def update(self, val, n=1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count


if __name__ == '__main__':
    main()
